#1 eks create

#2 eks apply kubeconfig

#3 check connect
kubectl get nodes

#5.1 Apply Secrets
kubectl apply -f aws-secret.yml
kubectl apply -f env-secret.yml

#5.2 Apply Deployments
kubectl apply -f backend-feed-deployment.yml
kubectl apply -f backend-user-deployment.yml
kubectl apply -f reverseproxy-deployment.yml

#5.3 Apply Services
kubectl apply -f backend-feed-service.yml
kubectl apply -f backend-user-service.yml
kubectl apply -f reverseproxy-service.yml

#5.4.1 Expose pubReverse
kubectl expose deployment reverseproxy --type=LoadBalancer --name=publicreverseproxy

#5.4.2 Get pubReverse hosting and then replace hosting of FE/Env files
kubectl get services

#5.5 Apply late FE 
kubectl apply -f frontend-deployment.yml
kubectl apply -f frontend-service.yml

#5.6.1 Expose pubFE
kubectl expose deployment frontend --type=LoadBalancer --name=publicfrontend

#5.6.2 Get pubFE hosting and replace hosting of env-configmap.yml
kubectl get services

#5.7 Apply the last config
kubectl apply -f env-configmap.yml

#5.8.1 For docker login if needing (then typing password)
docker login --username=henrynguyen17

#5.8.2 update docker FE to v2
docker build . -t henrynguyen17/udagram-frontend:v2
docker push henrynguyen17/udagram-frontend:v2
kubectl set image deployment frontend frontend=henrynguyen17/udagram-frontend:v2

#5.9 Travis FE deployment tag is v2 and commit code.

#6.0 Complete scaling
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yml
kubectl autoscale deployment backend-feed --cpu-percent=70 --min=1 --max=10
kubectl autoscale deployment backend-user --cpu-percent=70 --min=1 --max=10
kubectl get hpa
kubectl describe hpa


#Notes:
#1. if pod has bad status you can rerun
kubectl rollout restart deployment <deployment_name> -n <namespace>

#2. Delete cluster when finishing
eksctl delete cluster -f setup-cluster.yml --profile Admin

#3. all pods must be running after applying Services
kubectl get pods

#4. view deployments if needing
kubectl get deployments

#5. view pod log if feel something strange
#5.1 view log: kubectl get <your pod>
#5.2 force run and view log: kubectl logs -f <your pod>